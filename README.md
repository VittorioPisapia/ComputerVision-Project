# Comparative Analysis of Feature Extraction Techniques for Robust Deepfake Image Detection
## Table of contents
## Introduction to the Problem
Deepfake image detection has become a critical challenge in computer vision due to the growing ease of generating highly realistic synthetic media using artificial intelligence. Detecting such manipulated content demands robust techniques capable of distinguishing between authentic and generated images. This project aims to investigate and compare various feature extraction techniques for deepfake image detection. By evaluating the performance of traditional feature extraction methods, such as Local Binary Patterns (LBP) and Histogram of Oriented Gradients (HOG), alongside a neural network-based end-to-end model, the project tries to identify the strengths and weaknesses of each approach.

## Human Performance
24 participants were tested using the same dataset employed for training and evaluation. Each participant was presented with 10 images per test, and the time required to complete each test was recorded.
Out of 132 total runs, the mean accuracy was 6.59 correct answers per test, while the average time required was 49 seconds per test.
<p align="center">
    <img src="https://github.com/VittorioPisapia/ComputerVision-Project/blob/main/images/app1.png" alt="Example Image" style="width:660px;"/>
</p>

## Feature extractor
### LBP
LBP is a texture descriptor that captures local features by encoding the relationship between a pixel and its neighboring pixels.
#### Advantages
- **Captures fine-grained Textures**: LBP could be effective in detecting irregular patterns or inconsistencies in skin texture due to its focus in local texture.
- **Computational Efficiency**: LBP is computationally lightweight, making it well-suited for analyzing large datasets.
- **Baseline for Comparison**: due to its low computational cost, it will be used as a baseline for comparison.
#### Limitations
- Struggles with high-level features, such as global structures, limiting its ability to capture complex anomalies.

### HOG
HOG focuses on capturing the gradient orientation distributions of an image, making it effective in detecting shapes and edges. 
#### Advantages
- **Edge and Shape information**: Highlights distortions and artifacts in edges and contours.
- **Complementary to LBP**: Combining HOG and LBP can provide a more comprehensive image representation.
#### Limitations
- Less effective at capturing fine-grained texture details.

### SIFT
SIFT identifies and describes local keypoints in an image.
#### Advantages
- **Focus on keypoints**: Ideal for analyzing specific regions with anomalies rather than the whole image.
- **Robustness**: Performs well under transformations like scaling and rotation.
#### Limitations
- Computationally intensive compared to simpler methods.
- The descriptors generated by SIFT are high-dimensional (128 per key point), leading to large feature vectors if many key points are detected.

### CNN
A deep neural network is designed to perform feature extraction and classification in a single pipeline. This end-to-end model is trained directly on raw image data, enabling it to learn hierarchical features through multiple convolutional layers.
#### Advantages
- **Feature Extraction**: Automatically extracts features at multiple levels, from low-level textures to high-level patterns.
- **Integrated Workflow**: Combines feature extraction and classification.
#### Limitations
- Requires significant computational power and large datasets for effective training.
- Functions as a 'black box,' making it difficult to explain decisions.
#### Model Architecture
<p align="center">
    <img src="https://github.com/VittorioPisapia/ComputerVision-Project/blob/main/images/CNN_model_architecture.png" alt="Example Image" style="width:660px;"/>
</p>

## Dataset
The dataset for this project includes both real and fake images:
- Real images: Samples were sourced from Flickr-Faces-HQ (FFHQ), provided by Nvidia.
- Fake images: Faces were sampled by the “1 Million Face Faces” dataset, created with StyleGan and provided by Bojan Tunguz.

## Evaluation Metrics 
- **Accuracy**: Evaluated using the F1-score to measure the balance between precision and recall in the classification.
- **Computational Efficiency**: Feature extraction times and training times will be compared for each method to assess computational performance.
- **Robustness to Adversarial Attacks**: Test on adversarial examples generated with Fast Gradient Method (FGM) and Carlini and Wagner L2 Method (CL2).




